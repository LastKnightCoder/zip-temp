{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba712aa-1118-4c44-b567-e4df9b34b2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 24 19:34:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 495.44       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8    27W / 350W |      0MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8624fe82-df19-4e6f-bb15-099ee33d1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import cv2 as cv\n",
    "import os.path as path\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fab5fd2-8950-4673-b733-94ea8b278fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, origin_root, train_root):\n",
    "        super().__init__()\n",
    "        self.origin_root = origin_root\n",
    "        self.train_root = train_root\n",
    "        self.origin_files = os.listdir(self.origin_root)\n",
    "        self.train_files = os.listdir(self.train_root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.origin_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        origin_data = cv.imread(path.join(self.origin_root, self.origin_files[index]))\n",
    "        train_data = cv.imread(path.join(self.train_root, self.train_files[index]))\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        origin_data = to_tensor(origin_data)[0].reshape((1, 678, 384))\n",
    "        return origin_data, to_tensor(train_data)[0].reshape((1, 678, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8beebc-3f6d-47eb-989b-0935ffd37617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.proj = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if torch.any(torch.isnan(x)):\n",
    "            torch.isnan(x)\n",
    "        residual = x\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        if residual.size()[1] != out.size()[1]:\n",
    "            residual = self.proj(residual)\n",
    "        out += residual\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # input is (1) x 678 x 384\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.InstanceNorm2d(64, affine=True),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (64) x 678 x 384\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (128) x 339 x 192\n",
    "            ResNetBlock(128, 128),\n",
    "            ResNetBlock(128, 256, stride=2),\n",
    "            ResNetBlock(256, 256),\n",
    "            ResNetBlock(256, 512, stride=2),\n",
    "            # state size. (512) x 85 x 48\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(256, affine=True),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (256) x 170 x 96\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(128, affine=True),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (128) x 340 x 192\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(64, affine=True),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (64) x 680 x 384\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=7, stride=1, padding=(4, 3)),\n",
    "            nn.Tanh()\n",
    "            # output is (1) x 678 x 384\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs) + inputs\n",
    "\n",
    "\n",
    "    \n",
    "class StandardDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StandardDiscriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # input is (1) x 678 x 384\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (64) x 178 x 89\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (128) x 89 x 44\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(41 * 23, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4356d81d-3143-4dc5-b22a-8784f19effc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model_name = 'sd-gan/standard-generatorg5d1.pth'\n",
    "discriminator_model_name = 'sd-gan/standard-discriminatorg5d1.pth'\n",
    "start_point = 0\n",
    "\n",
    "\n",
    "class StandarnGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StandarnGAN, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.G = Generator().to(self.device)\n",
    "        self.D = StandardDiscriminator().to(self.device)\n",
    "        self.batch_size = 8\n",
    "        self.generator_iter = 500\n",
    "        self.critic_iter = 1\n",
    "        self.gen_iters = 5\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "        dataset = ImageDataset(origin_root='dataset/train/images',\n",
    "                               train_root='dataset/train/labels')\n",
    "        self.data_loader = torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.data = self.get_infinite_batches()\n",
    "\n",
    "        self.loss_func = nn.BCELoss()\n",
    "\n",
    "        self.init_model()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.generator_iter):\n",
    "            print(f'Epoch: {epoch + 1 + start_point} / {self.generator_iter + start_point} ============================')\n",
    "            begin = time.time()\n",
    "            # 训练判别器\n",
    "            for p in self.D.parameters():\n",
    "                p.requires_grad = True\n",
    "                \n",
    "            d_loss_real = 0\n",
    "            d_loss_fake = 0\n",
    "            g_loss_fake = 0\n",
    "            for d_iter in range(self.critic_iter):\n",
    "                self.D.zero_grad()\n",
    "                inputs, reals = next(self.data)\n",
    "\n",
    "                d_loss_real = self.D(reals)\n",
    "                l1 = self.loss_func(d_loss_real, torch.ones(d_loss_real.size()).to(self.device))\n",
    "\n",
    "                fakes = self.G(inputs)\n",
    "                d_loss_fake = self.D(fakes)\n",
    "                l2 = self.loss_func(d_loss_fake, torch.zeros(d_loss_fake.size()).to(self.device))\n",
    "\n",
    "                d_loss = (l1 + l2) / 2\n",
    "                d_loss.backward()\n",
    "\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "            # 固定判别器，训练生成器\n",
    "            for p in self.D.parameters():\n",
    "                p.requires_grad = False\n",
    "            \n",
    "            for g_iter in range(self.gen_iters):\n",
    "                self.G.zero_grad()\n",
    "                inputs, _ = next(self.data)\n",
    "                # if inputs.size()[0] != self.batch_size:\n",
    "                #     inputs, _ = next(self.data)\n",
    "                fakes = self.G(inputs)\n",
    "                g_loss_fake = self.D(fakes)\n",
    "                g_loss = self.loss_func(g_loss_fake, torch.ones(g_loss_fake.size()).to(self.device))\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "            print(f'D loss: {d_loss.item()}, G loss: {g_loss.item()}, cost time: {time.time() - begin}')\n",
    "            print(f'd_loss_real: {d_loss_real.mean().item()}, d_loss_fake: {d_loss_fake.mean().item()}, g_loss_fake: {g_loss_fake.mean().item()}')\n",
    "            self.save_model()\n",
    "            \n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                torch.save(self.G.state_dict(), f'sd-gan/sd-generatorg5d1-{epoch + 1 + start_point}.pth')\n",
    "                torch.save(self.D.state_dict(), f'sd-gan/sd-discriminatorg5d1-{epoch + 1 + start_point}.pth')\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.G.state_dict(), generator_model_name)\n",
    "        torch.save(self.D.state_dict(), discriminator_model_name)\n",
    "        print(f'Models save to {generator_model_name} & {discriminator_model_name} ')\n",
    "\n",
    "    def init_model(self):\n",
    "        if os.path.exists(generator_model_name) and os.path.exists(discriminator_model_name):\n",
    "            self.G.load_state_dict(torch.load(generator_model_name))\n",
    "            self.D.load_state_dict(torch.load(discriminator_model_name))\n",
    "            print(f'Models load from {generator_model_name} & {discriminator_model_name}')\n",
    "        else:\n",
    "            print('No trained_models found, init new trained_models')\n",
    "            self.G.apply(self.weights_init)\n",
    "            self.D.apply(self.weights_init)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.xavier_normal_(m.weight.data)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "    def get_infinite_batches(self):\n",
    "        while True:\n",
    "            for i, (inputs, reals) in enumerate(self.data_loader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                reals = reals.to(self.device)\n",
    "                yield inputs, reals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c41fe-4986-4130-942b-dcd59fae1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StandarnGAN()\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
